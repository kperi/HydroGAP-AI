{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install hydrogapai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files: 100%|██████████████████████████████████████████████████████████████| 49/49 [41:09<00:00, 50.40s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed for station_851.0_cleaned.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm  # Import tqdm for the progress bar\n",
    "import gc\n",
    "from hydrogapai.gap_prediction import (\n",
    "    predict_station_gaps,\n",
    "    plot_fully,\n",
    "    plot_yearly,\n",
    ")\n",
    "\n",
    "#Change this folder path to your own\n",
    "folder_path = r\"<address_of_folder_with_csv_dataset(s)>\"\n",
    "all_metrics_folder = os.path.join(folder_path, 'all_metrics')\n",
    "os.makedirs(all_metrics_folder, exist_ok=True)\n",
    "# Define the model you want to use: lr  = linear regression = sdgRegressor;\n",
    "#                                   knn = k nearest neighbours\n",
    "#                                   svr = support vector regression\n",
    "#                                   rf  = random forest\n",
    "#                                   xgb = extreme gradient boost\n",
    "#                                   lgb = light gradient boostt\n",
    "model_type = \"rf\"\n",
    "# Define the number of lag times for partial auto correlation ('obsdis' streamflow values)\n",
    "num_pacf_lags=3\n",
    "# Define the start of the lag time for cross correlation ('tp' precipitation values)\n",
    "plag_start=1\n",
    "# Define the number of lag times for cross correlation ('tp' precipitation values)\n",
    "num_ccf_lags=30\n",
    "\n",
    "# Define if you want to do hyper-parameter optimization\n",
    "hyper_opt=False\n",
    "\n",
    "# Get a list of all CSV files in the folder\n",
    "station_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "\n",
    "#Define start and end date of a plot if you need a specific range\n",
    "plot_start_date = None\n",
    "plot_end_date = None\n",
    "\n",
    "headers = [\"input_file_path\", \n",
    "           \"missing_rate\",\n",
    "           \"min_gap_length\", \n",
    "           \"mean_gap_length\", \n",
    "           \"median_gap_length\", \n",
    "           \"max_gap_length\",\n",
    "           \"std_gap_length\", \n",
    "           \"range_gap_length\", \n",
    "           \"gap_density\", \n",
    "           \"nr_gap_days\", \n",
    "           \"nr_gaps\", \n",
    "           \"min_value\", \n",
    "           \"mean_value\", \n",
    "           \"median_value\", \n",
    "           \"max_value\", \n",
    "           \"std_value\", \n",
    "           \"range_value\", \n",
    "           \"skew_value\", \n",
    "           \"kurtosis_value\", \n",
    "           \"Q_lags\", \n",
    "           \"Q_lags_Coefficients\", \n",
    "           \"P_lags\", \n",
    "           \"P_lags_Coefficients\",\n",
    "           \"R2_score\", \n",
    "           \"RMSE\", \n",
    "           \"Mean Bias Error\", \n",
    "           \"MAE\", \n",
    "           \"Percentage Error (%)\", \n",
    "           \"Nash-Sutcliffe\", \n",
    "           \"Index of Agreement\", \n",
    "           \"Correlation Coefficient\", \n",
    "           \"KGE Overall\", \n",
    "           \"KGE Correlation\", \n",
    "           \"KGE Bias\", \n",
    "           \"KGE Variability\"\n",
    "]\n",
    "\n",
    "# Create log CSV file at the start with headers for metrics of all datasets/csv files\n",
    "current_datetime = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "output_file = os.path.join(all_metrics_folder, f\"_all_metrics_{model_type}.csv\")\n",
    "log_file = os.path.join(all_metrics_folder, f\"log_file_{model_type}_{current_datetime}.txt\")\n",
    "\n",
    "# Function to check if headers exist\n",
    "def check_headers_exist(file_path, headers):\n",
    "    if not os.path.exists(file_path):\n",
    "        return False\n",
    "    with open(file_path, 'r', newline='') as file:\n",
    "        reader = csv.reader(file)\n",
    "        existing_headers = next(reader, None)\n",
    "        return existing_headers == headers\n",
    "\n",
    "headers_exist = check_headers_exist(output_file, headers)# Check if headers exist\n",
    "with open(output_file, mode='a', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=headers)\n",
    "    # Only write the headers if they don't exist\n",
    "    if not headers_exist:\n",
    "        writer.writeheader()\n",
    "\n",
    "with tqdm(total=len(station_files), desc=\"Processing Files\", unit=\"file\") as pbar:\n",
    "    for station_file in station_files:\n",
    "        try:\n",
    "            # Open log file and append the station file path as a new line\n",
    "            with open(log_file, mode='a') as log:\n",
    "                log.write(f\"Processing file: {station_file}\\n\")\n",
    "            \n",
    "            # Extract the filename from the input file path\n",
    "            filename = os.path.basename(station_file)\n",
    "            filename_no_ext = filename.rsplit('.', 1)[0]\n",
    "            results_folder = os.path.join(\n",
    "                os.path.dirname(station_file), \n",
    "                f\"results_{filename_no_ext}\"\n",
    "            )\n",
    "            os.makedirs(results_folder, exist_ok=True)\n",
    "            \n",
    "            all_combined_dfs, val_full, metrics_gaps, real_predictions = predict_station_gaps(\n",
    "                station_file, results_folder, model_type=model_type, hyper_opt=hyper_opt, num_pacf_lags=num_pacf_lags,\n",
    "                plag_start=plag_start, num_ccf_lags=num_ccf_lags\n",
    "            )\n",
    "\n",
    "            # Save combined plot for the full dataset\n",
    "            plot_fully(\n",
    "                results_folder,\n",
    "                val_full,\n",
    "                real_predictions,\n",
    "                filename,\n",
    "                model_type,\n",
    "                plot_start_date,\n",
    "                plot_end_date,\n",
    "            )\n",
    "\n",
    "            # Save combined plot per year\n",
    "            plot_yearly(results_folder, val_full, real_predictions, filename, model_type)\n",
    "\n",
    "            # Save the dataset with the real gaps filled with predictions\n",
    "            output_csv_filename = os.path.join(results_folder, f\"pred_{filename}\")\n",
    "            val_full = val_full.drop(columns=[\"year\"])\n",
    "            val_full.to_csv(output_csv_filename, index=True)\n",
    "\n",
    "            # Create CSV file at the start with headers\n",
    "            output_file1 = os.path.join(results_folder, f'{filename}_metrics_{model_type}.csv')\n",
    "            # Append the new metrics to the existing CSV filea\n",
    "            with open(output_file1, mode='a', newline='') as file:\n",
    "                writer = csv.DictWriter(file, fieldnames=headers)\n",
    "                writer.writeheader()\n",
    "                writer.writerow(metrics_gaps)\n",
    "            #os.makedirs(results_folder, exist_ok=True)\n",
    "            with open(output_file, mode='a', newline='') as file:\n",
    "                writer = csv.DictWriter(file, fieldnames=headers)\n",
    "                #writer.writeheader()\n",
    "                writer.writerow(metrics_gaps)\n",
    "        except Exception as e:\n",
    "            # Log the error and continue with the next file\n",
    "            with open(log_file, mode='a') as log:\n",
    "                log.write(f\"Error processing file: {station_file}\\n\")\n",
    "                log.write(f\"Error details: {str(e)}\\n\")\n",
    "        gc.collect\n",
    "        # Update the progress bar\n",
    "        pbar.update(1)\n",
    "        \n",
    "print(f\"Processing completed for {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hydrogap-ai_env)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
